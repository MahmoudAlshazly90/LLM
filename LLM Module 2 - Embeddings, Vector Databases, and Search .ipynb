{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68007d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu==1.7.4\n",
      "  Obtaining dependency information for faiss-cpu==1.7.4 from https://files.pythonhosted.org/packages/3e/8f/55f8cd863c678a703aa3b97e5f4511cfd2c52987ba05459afdcdec76eeb3/faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting chromadb==0.3.21\n",
      "  Obtaining dependency information for chromadb==0.3.21 from https://files.pythonhosted.org/packages/85/df/74642bf2fa83a4b6a00402636339ccbebb5c85b00dad93f93fb6bbb13fc9/chromadb-0.3.21-py3-none-any.whl.metadata\n",
      "  Using cached chromadb-0.3.21-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (1.10.8)\n",
      "Collecting hnswlib>=0.7 (from chromadb==0.3.21)\n",
      "  Using cached hnswlib-0.8.0.tar.gz (36 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.21)\n",
      "  Obtaining dependency information for clickhouse-connect>=0.5.7 from https://files.pythonhosted.org/packages/68/69/09b3a4e53f5d3d770e9fa70f6f04642cdb37cc76d37279c55fd4e868f845/clickhouse_connect-0.7.19-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached clickhouse_connect-0.7.19-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting sentence-transformers>=2.2.2 (from chromadb==0.3.21)\n",
      "  Obtaining dependency information for sentence-transformers>=2.2.2 from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting duckdb>=0.7.1 (from chromadb==0.3.21)\n",
      "  Obtaining dependency information for duckdb>=0.7.1 from https://files.pythonhosted.org/packages/99/cc/e7ac5431a57e6a721f66dc423be58275ad48c9aecc1a12a5f4692e3da4b5/duckdb-1.0.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached duckdb-1.0.0-cp311-cp311-win_amd64.whl.metadata (781 bytes)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (0.110.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from chromadb==0.3.21) (1.24.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.3.21)\n",
      "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/94/e2/b7112f760e9e49b8a85a1f512d0712f3180cac4f7df84604b6dbc42cfdf3/posthog-3.6.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached posthog-3.6.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2023.7.22)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (1.26.16)\n",
      "Requirement already satisfied: pytz in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2023.3.post1)\n",
      "Requirement already satisfied: zstandard in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (0.19.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from fastapi>=0.85.1->chromadb==0.3.21) (0.37.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from fastapi>=0.85.1->chromadb==0.3.21) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.21) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.21) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.21) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.3.21)\n",
      "  Obtaining dependency information for monotonic>=1.5 from https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl.metadata\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.21)\n",
      "  Obtaining dependency information for backoff>=1.10.0 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb==0.3.21) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb==0.3.21) (2.10)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers>=2.2.2->chromadb==0.3.21)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (0.15.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (9.4.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.9.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.4.6)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/14/e4/20d28dfe7f5b5603b6b04c33bb88662ad749de51f0c539a561f235f42666/httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (0.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.21) (6.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/8a/8b/badd9247d6ec25f5f634a9b3d0d92e39c045824ec7e8afcedca8ee52c1e2/watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
      "  Obtaining dependency information for websockets>=10.4 from https://files.pythonhosted.org/packages/12/40/46967d00640e6c3231b73d310617927a11c91bcc044dd5a0860a3c457c33/websockets-13.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached websockets-13.0.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.2.2->chromadb==0.3.21) (2023.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.2.2->chromadb==0.3.21) (23.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.85.1->chromadb==0.3.21) (3.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.1.2)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers>=2.2.2->chromadb==0.3.21)\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2022.7.9)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.2->chromadb==0.3.21)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/21/4f/5ee44681c7ea827f9d3c104ca429865b41c05a4163eff7f0599152c2e682/safetensors-0.4.4-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached safetensors-0.4.4-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.2.2->chromadb==0.3.21)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting fsspec (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/5e/44/73bea497ac69bafde2ee4269292fa3b41f1198f4bb7bbaaabde30ad29d4a/fsspec-2024.6.1-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.21) (2.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.85.1->chromadb==0.3.21) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mahmoud alshazly\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.3.0)\n",
      "Using cached faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "Using cached chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
      "Using cached clickhouse_connect-0.7.19-cp311-cp311-win_amd64.whl (238 kB)\n",
      "Using cached duckdb-1.0.0-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "Using cached posthog-3.6.0-py2.py3-none-any.whl (50 kB)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Using cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl (277 kB)\n",
      "Using cached websockets-13.0.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached safetensors-0.4.4-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Building wheels for collected packages: hnswlib\n",
      "  Building wheel for hnswlib (pyproject.toml): started\n",
      "  Building wheel for hnswlib (pyproject.toml): finished with status 'error'\n",
      "Failed to build hnswlib\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hnswlib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'hnswlib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hnswlib\n",
      "ERROR: Could not build wheels for hnswlib, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu==1.7.4 chromadb==0.3.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "428bf2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108769</th>\n",
       "      <td>NATION</td>\n",
       "      <td>https://www.vanguardngr.com/2020/08/pdp-govern...</td>\n",
       "      <td>vanguardngr.com</td>\n",
       "      <td>2020-08-08 02:40:00</td>\n",
       "      <td>PDP governors’ forum urges security agencies t...</td>\n",
       "      <td>en</td>\n",
       "      <td>108769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108770</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>https://www.patentlyapple.com/patently-apple/2...</td>\n",
       "      <td>patentlyapple.com</td>\n",
       "      <td>2020-08-08 01:27:12</td>\n",
       "      <td>In Q2-20, Apple Dominated the Premium Smartpho...</td>\n",
       "      <td>en</td>\n",
       "      <td>108770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108771</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.belfastlive.co.uk/news/health/coro...</td>\n",
       "      <td>belfastlive.co.uk</td>\n",
       "      <td>2020-08-12 17:01:00</td>\n",
       "      <td>Coronavirus Northern Ireland: Full breakdown s...</td>\n",
       "      <td>en</td>\n",
       "      <td>108771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108772</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>https://www.thenews.com.pk/latest/696364-paul-...</td>\n",
       "      <td>thenews.com.pk</td>\n",
       "      <td>2020-08-05 04:59:00</td>\n",
       "      <td>Paul McCartney details post-Beatles distress a...</td>\n",
       "      <td>en</td>\n",
       "      <td>108772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108773</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>https://www.balls.ie/football/shane-duffy-brig...</td>\n",
       "      <td>balls.ie</td>\n",
       "      <td>2020-08-09 10:25:26</td>\n",
       "      <td>Report: Talks Underway To Keep Shane Duffy In ...</td>\n",
       "      <td>en</td>\n",
       "      <td>108773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108774 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                topic                                               link  \\\n",
       "0             SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...   \n",
       "1             SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...   \n",
       "2             SCIENCE  https://www.express.co.uk/news/science/1322607...   \n",
       "3             SCIENCE  https://www.ndtv.com/world-news/glaciers-could...   \n",
       "4             SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...   \n",
       "...               ...                                                ...   \n",
       "108769         NATION  https://www.vanguardngr.com/2020/08/pdp-govern...   \n",
       "108770       BUSINESS  https://www.patentlyapple.com/patently-apple/2...   \n",
       "108771         HEALTH  https://www.belfastlive.co.uk/news/health/coro...   \n",
       "108772  ENTERTAINMENT  https://www.thenews.com.pk/latest/696364-paul-...   \n",
       "108773         SPORTS  https://www.balls.ie/football/shane-duffy-brig...   \n",
       "\n",
       "                   domain       published_date  \\\n",
       "0          eurekalert.org  2020-08-06 13:59:45   \n",
       "1                pulse.ng  2020-08-12 15:14:19   \n",
       "2           express.co.uk  2020-08-13 21:01:00   \n",
       "3                ndtv.com  2020-08-03 22:18:26   \n",
       "4               thesun.ie  2020-08-12 19:54:36   \n",
       "...                   ...                  ...   \n",
       "108769    vanguardngr.com  2020-08-08 02:40:00   \n",
       "108770  patentlyapple.com  2020-08-08 01:27:12   \n",
       "108771  belfastlive.co.uk  2020-08-12 17:01:00   \n",
       "108772     thenews.com.pk  2020-08-05 04:59:00   \n",
       "108773           balls.ie  2020-08-09 10:25:26   \n",
       "\n",
       "                                                    title lang      id  \n",
       "0       A closer look at water-splitting's solar fuel ...   en       0  \n",
       "1       An irresistible scent makes locusts swarm, stu...   en       1  \n",
       "2       Artificial intelligence warning: AI will know ...   en       2  \n",
       "3        Glaciers Could Have Sculpted Mars Valleys: Study   en       3  \n",
       "4       Perseid meteor shower 2020: What time and how ...   en       4  \n",
       "...                                                   ...  ...     ...  \n",
       "108769  PDP governors’ forum urges security agencies t...   en  108769  \n",
       "108770  In Q2-20, Apple Dominated the Premium Smartpho...   en  108770  \n",
       "108771  Coronavirus Northern Ireland: Full breakdown s...   en  108771  \n",
       "108772  Paul McCartney details post-Beatles distress a...   en  108772  \n",
       "108773  Report: Talks Underway To Keep Shane Duffy In ...   en  108773  \n",
       "\n",
       "[108774 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.read_csv(r\"E:\\AI\\LLM COURSE\\archive\\labelled_newscatcher_dataset.csv\", sep=\";\")\n",
    "pdf[\"id\"] = pdf.index\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d990413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmoud Alshazly\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1608\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m      3\u001b[0m pdf_subset \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexample_create_fn\u001b[39m(doc1: pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InputExample:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fullname, get_device_name, import_from_string\n\u001b[0;32m     21\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\model_card.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1608\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "pdf_subset = pdf.head(1000)\n",
    "\n",
    "def example_create_fn(doc1: pd.Series) -> InputExample:\n",
    "    \"\"\"\n",
    "    Helper function that outputs a sentence_transformer guid, label, and text\n",
    "    \"\"\"\n",
    "    return InputExample(texts=[doc1])\n",
    "\n",
    "faiss_train_examples = pdf_subset.apply(\n",
    "    lambda x: example_create_fn(x[\"title\"]), axis=1\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe8bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
